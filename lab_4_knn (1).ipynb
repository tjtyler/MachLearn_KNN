{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVL7_bgmIAPR"
      },
      "source": [
        "# K-Nearest Neighbor Lab\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6ZbYjZZZ_yLV"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ipdb"
      ],
      "metadata": {
        "id": "LiN5QbkRk5Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTeXAISqJGyu",
        "outputId": "1126cc08-428f-4444-c657-9bc29949bb7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def estimate_coef(x, y):\n",
        "\t# number of observations/points\n",
        "\tn = np.size(x)\n",
        "\n",
        "\t# mean of x and y vector\n",
        "\tm_x = np.mean(x)\n",
        "\tm_y = np.mean(y)\n",
        "\n",
        "\t# calculating cross-deviation and deviation about x\n",
        "\tSS_xy = np.sum(y*x) - n*m_y*m_x\n",
        "\tSS_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "\t# calculating regression coefficients\n",
        "\tb_1 = SS_xy / SS_xx\n",
        "\tb_0 = m_y - b_1*m_x\n",
        "\n",
        "\treturn (b_0, b_1)\n",
        "\n",
        "def plot_regression_line(x, y, b):\n",
        "\t# plotting the actual points as scatter plot\n",
        "\tplt.scatter(x, y, color = \"m\",\n",
        "\t\t\tmarker = \"o\", s = 30)\n",
        "\n",
        "\t# predicted response vector\n",
        "\ty_pred = b[0] + b[1]*x\n",
        "\n",
        "\t# plotting the regression line\n",
        "\tplt.plot(x, y_pred, color = \"g\")\n",
        "\n",
        "\t# putting labels\n",
        "\tplt.xlabel('x')\n",
        "\tplt.ylabel('y')\n",
        "\n",
        "\t# function to show plot\n",
        "\tplt.show()\n",
        "\n",
        "def main():\n",
        "\t# observations / data\n",
        "\t# x = np.array([.3,-.3,.9,1])\n",
        "\t# y = np.array([.8,1.6,0,1])\n",
        "\n",
        "  x = np.array([.3,-.3,.9,1])\n",
        "  y = np.array([.8,1.6,0,1])\n",
        "\n",
        "\t# estimating coefficients\n",
        "  b = estimate_coef(x, y)\n",
        "  print(\"Estimated coefficients:\\nb_0 = {} \\\n",
        "    \\nb_1 = {}\".format(b[0], b[1]))\n",
        "\n",
        "\t# plotting regression line\n",
        "  plot_regression_line(x, y, b)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "QIE-ZbneqOT1",
        "outputId": "056f05a7-74da-4ce4-d08a-0577cd1efb97"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated coefficients:\n",
            "b_0 = 1.223448275862069     \n",
            "b_1 = -0.7862068965517242\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcEPx5VIORj"
      },
      "source": [
        "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
        "\n",
        "### Code requirements\n",
        "- Use Euclidean distance to decide closest neighbors. \n",
        "- Include optional distance weighting for both algorithms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_a2KSZ_7AN0G"
      },
      "outputs": [],
      "source": [
        "# import ipdb; \n",
        "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
        "    def __init__(self, Type='classification', columntype=[], weight_type='inverse_distance'): ## add parameters here\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
        "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
        "        \"\"\"\n",
        "        self.columntype = columntype #Note This won't be needed until part 5\n",
        "        self.weight_type = weight_type\n",
        "        self.Type = Type\n",
        "\n",
        "    def fit(self, X, y, k=3):\n",
        "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "            y (array-like): A 2D numpy array with the training targets\n",
        "        Returns:\n",
        "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
        "        \"\"\"\n",
        "        self.X = X # 2D numpy array\n",
        "        self.y = y # 1D numpy array\n",
        "        self.k = k # int\n",
        "\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\" Predict all classes for a dataset X\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
        "        Returns:\n",
        "            array, shape (n_samples,)\n",
        "                Predicted target values per element in X.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "          inst = X[i]\n",
        "          # ipdb.set_trace()\n",
        "          dists = self.calc_euclid_dist(self.X, inst=inst) \n",
        "          neighbors = np.argsort(dists)[:self.k]\n",
        "          dists = dists[neighbors]\n",
        "          y = self.y[neighbors] \n",
        "          wts = np.ones_like(y)\n",
        "\n",
        "          if self.weight_type == 'inverse_distance':\n",
        "            wts = 1/np.square(dists) \n",
        "            if self.columntype[-1] == 'cat':\n",
        "              wt_sums = np.bincount(y, wts)\n",
        "              if self.Type == 'classification': \n",
        "                pred = wt_sums.argmax()\n",
        "                predictions.append(pred)\n",
        "            else:\n",
        "              pred = wts @ y\n",
        "              pred = pred / np.sum(wts)\n",
        "              predictions.append(pred)\n",
        "              \n",
        "          else:\n",
        "            if self.columntype[-1] == 'cat':\n",
        "              cls_counts = np.bincount(y)\n",
        "              pred = cls_counts.argmax()\n",
        "              predictions.append(pred)\n",
        "            else:\n",
        "              pred = np.mean(y)\n",
        "              predictions.append(pred)\n",
        "            \n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def calc_euclid_dist(self, X, inst):\n",
        "      return np.linalg.norm(X - inst, axis=1)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 2D numpy array with targets\n",
        "        Returns:\n",
        "            score : float\n",
        "                Mean accuracy of self.predict(X) wrt. y.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(X=X)\n",
        "        score = 0\n",
        "        for i in range(len(predictions)):\n",
        "          if y[i] == predictions[i]:\n",
        "            score += 1\n",
        "        return score / len(predictions)\n",
        "        \n",
        "    def score_mse(self, X, y):\n",
        "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
        "        Args:\n",
        "            X (array-like): A 2D numpy array with data, excluding targets\n",
        "            y (array-like): A 2D numpy array with targets\n",
        "        Returns:\n",
        "            score : float\n",
        "                Mean accuracy of self.predict(X) wrt. y.\n",
        "        \"\"\"\n",
        "        predictions = self.predict(X=X)\n",
        "        predictions = np.array(predictions)\n",
        "        return ((predictions - y)**2).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkIIsoyQUR6-"
      },
      "source": [
        "## 1.1 Debug and Evaluation\n",
        "\n",
        "Debug and Evaluate your model using the parameters below:\n",
        "\n",
        "- Use distance weighting\n",
        "- KNN = 3 (three nearest neighbors)\n",
        "- Don’t normalize the data\n",
        "- Use Euclidean Distance\n",
        "\n",
        "---\n",
        "\n",
        "### 1.1.1 Debug\n",
        "\n",
        "- Use this [glass training set](https://byu.instructure.com/courses/14142/files?preview=4660939) and this [glass test set](https://byu.instructure.com/courses/14142/files?preview=4660941)\n",
        "- Use distance weighting\n",
        "- KNN = 3 (three nearest neighbors)\n",
        "- Don’t normalize the data\n",
        "- Use Euclidean Distance\n",
        "\n",
        "Expected Results:\n",
        "- Not using inverse weighted distancing = roughly [68.29%]\n",
        "- Link to [glass no_inverse debug solution](https://byu.instructure.com/courses/14142/files?preview=4660947)\n",
        "\n",
        "- Using inverse weighted distancing = roughly [74.39%]\n",
        "- Link to [glass inverse debug solution](https://byu.instructure.com/courses/14142/files?preview=4660954)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1MJ5e5PVUR6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e910bf86-8b70-42a9-9181-4c7330bce3a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no weighting accuracy:  0.6829268292682927\n",
            "inverse weighting accuracy:  0.7439024390243902\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Load glass data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/glass_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) # 1D array\n",
        "\n",
        "# Train on training set\n",
        "col_type=['real']*10\n",
        "col_type[9] = 'cat'\n",
        "knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "knn.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type)\n",
        "knn_wt.fit(X=X_train, y=y_train, k=3)\n",
        "# Predict on test set\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/glass_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "print('no weighting accuracy: ', knn.score(X=X_test,y=y_test))\n",
        "print('inverse weighting accuracy: ', knn_wt.score(X=X_test,y=y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkIvGrf8UR6_"
      },
      "source": [
        "### 1.1.2 Evaluate\n",
        "\n",
        "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
        "- Use this [diabetes training set](https://byu.instructure.com/courses/14142/files?preview=4660977) and this [diabetes test set](https://byu.instructure.com/courses/14142/files?preview=4660978)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Zkg5yWHbUR7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30aa1c1a-efd3-4534-ac0c-1b4d3f31168f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no weighting accuracy:  0.8411458333333334\n",
            "inverse weighting accuracy:  0.890625\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Load diabetes data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/diabetes_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) # 1D array\n",
        "\n",
        "col_type=['real']*9\n",
        "col_type[8] = 'cat'\n",
        "# Train on training set\n",
        "knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "knn.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type)\n",
        "knn_wt.fit(X=X_train, y=y_train, k=3)\n",
        "# Predict on test set\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/diabetes_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "print('no weighting accuracy: ', knn.score(X=X_test,y=y_test))\n",
        "print('inverse weighting accuracy: ', knn_wt.score(X=X_test,y=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vWiTdlbR2Xh"
      },
      "source": [
        "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
        "\n",
        "- Use this [magic telescope training set](https://byu.instructure.com/courses/14142/files?preview=4660988) and this [magic telescope test set](https://byu.instructure.com/courses/14142/files?preview=4660989) \n",
        "\n",
        "### 2.1\n",
        "- Try it with k=3 and without normalization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "4SSoasDQSKXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7f2321-c52d-492f-dcc3-ca2f833d6744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no weighting accuracy:  0.8082808280828083\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# Load magic telescope data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) # 1D array\n",
        "\n",
        "col_type=['real']*11\n",
        "col_type[10] = 'cat'\n",
        "# Train/Predict without normalization\n",
        "\n",
        "knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "knn.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type)\n",
        "knn_wt.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "# Predict on test set\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "print('no weighting accuracy: ', knn.score(X=X_test,y=y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IxDxrIAUR7B"
      },
      "source": [
        "### 2.2\n",
        "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4HFmpuf7UR7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d536d1b6-ca14-41ca-950e-c5718eb337c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no weighting accuracy:  0.8306330633063307\n"
          ]
        }
      ],
      "source": [
        "# Train/Predict with normalization\n",
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load magic telescope data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) # 1D array\n",
        "\n",
        "col_type=['real']*11\n",
        "col_type[10] = 'cat'\n",
        "\n",
        "# Train on training set\n",
        "knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "knn.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "# knn_wt = KNNClassifier(Type='classification',columntype=['real'*9])\n",
        "# knn_wt.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "# Predict on test set\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "print('no weighting accuracy: ', knn.score(X=X_test,y=y_test))\n",
        "# print('inverse weighting accuracy: ', knn_wt.score(X=X_test,y=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S3vCEV8UR7C"
      },
      "source": [
        "*Discuss the accuracy results of using normalized data vs. unnormalized data*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as can be seen from the output of the 2 cells above, normalizing the magic telescope data did improve the prediciton accuracy, but only by about 2%. Although it seems small (2%), it could make a significant impact on a project so it is best to normalize your data."
      ],
      "metadata": {
        "id": "7atTm0l3kUiE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojw1lbIaUR7C"
      },
      "source": [
        "### 2.3\n",
        "\n",
        "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
        "    - Use odd values of k from 1 to 15.\n",
        "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9VWD499UR7C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3254b65a-cab8-47fd-d3c9-0aa709ef736c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdf1713ec10>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Train/Predict with normalization using k=1,3,...,15\n",
        "accuracies = []\n",
        "ks = [1,3,5,7,9,11,13,15]\n",
        "col_type=['real']*11\n",
        "col_type[10] = 'cat'\n",
        "\n",
        "for i in range(1,16,2):\n",
        "  # Load magic telescope data\n",
        "  raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_train.arff')\n",
        "  df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "  np_arr = df_data.to_numpy()\n",
        "  enc = LabelEncoder()\n",
        "  scaler = MinMaxScaler()\n",
        "\n",
        "  X_train = np_arr[:,:-1].astype(float)\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  y_train = enc.fit_transform(np_arr[:,-1]) \n",
        "  # Train on training set\n",
        "  knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "  knn.fit(X=X_train, y=y_train, k=i)\n",
        "\n",
        "  raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_test.arff')\n",
        "  df_data = pd.DataFrame(raw_data[0])\n",
        "  np_arr = df_data.to_numpy()\n",
        "\n",
        "  X_test = np_arr[:,:-1].astype(float)\n",
        "  X_test = scaler.transform(X_test)\n",
        "  y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "  accuracies.append(knn.score(X=X_test,y=y_test))\n",
        "\n",
        "dictionary = {'Ks': ks, \"Accuracies\": accuracies}\n",
        "df = pd.DataFrame(dictionary)\n",
        "\n",
        "# Graph classification accuracy over k\n",
        "df.plot(x ='Ks', y='Accuracies', kind = 'line')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shD7pFHsUR7D"
      },
      "source": [
        "# For the rest of the experiments use only normalized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIRG42TgSR4x"
      },
      "source": [
        "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
        "\n",
        "- Use this [housing training set](https://byu.instructure.com/courses/14142/files?preview=4660994) and this [housing test set](https://byu.instructure.com/courses/14142/files?preview=4660995).\n",
        "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
        "    - Do not normalize regression output values\n",
        "- Graph MSE on the test set with odd values of k from 1 to 15\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KBGUn43ASiXW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "ad26510e-5a98-4192-98f0-4ad672c0fa7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best mse @ k = 5:  15.89698039215686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4f50569650>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Graph MSE over k\n",
        "\n",
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Train/Predict with normalization using k=1,3,...,15\n",
        "MSEs = []\n",
        "ks = [1,3,5,7,9,11,13,15]\n",
        "\n",
        "# Load housing price prediction data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = np_arr[:,-1]\n",
        "\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = np_arr[:,-1]\n",
        "col_type = ['real']*14\n",
        "col_type[3] = 'cat'\n",
        "\n",
        "for i in range(1,16,2):\n",
        "\n",
        "  # Train on training set\n",
        "  knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "  knn.fit(X=X_train, y=y_train, k=i)\n",
        "\n",
        "  MSEs.append(knn.score_mse(X=X_test,y=y_test))\n",
        "\n",
        "dictionary = {'Ks': ks, \"MSEs\": MSEs}\n",
        "df = pd.DataFrame(dictionary)\n",
        "\n",
        "knn = KNNClassifier(Type='classification',columntype=col_type, weight_type=\"no_weight\")\n",
        "knn.fit(X=X_train, y=y_train, k=5)\n",
        "print('best mse @ k = 5: ', knn.score_mse(X_test,y_test))\n",
        "# Graph classification accuracy over k\n",
        "df.plot(x ='Ks', y='MSEs', kind = 'line')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v19fpixqTe-7"
      },
      "source": [
        "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69R5jwdCUR7E"
      },
      "source": [
        "## 4.1 Magic Telescope Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZCPFUAGTS2sX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd507fa-8974-45f6-b6f6-b3a0075430f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: RuntimeWarning: divide by zero encountered in true_divide\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inverse weighting accuracy:  0.8310831083108311\n"
          ]
        }
      ],
      "source": [
        "# Train/Predict magic telescope using distance-weighted voting\n",
        "# Train/Predict with normalization\n",
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load magic telescope data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "col_type=['real']*11\n",
        "col_type[10] = 'cat'\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) # 1D array\n",
        "# Train on training set\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type)\n",
        "knn_wt.fit(X=X_train, y=y_train, k=3)\n",
        "\n",
        "# Predict on test set\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "print('inverse weighting accuracy: ', knn_wt.score(X=X_test,y=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bPS41IIUR7E"
      },
      "source": [
        "## 4.2 Housing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "YkqwfZ0AUR7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8f6542-c461-447b-c2f4-695b8856b1fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inverse weighting mse:  12.119627591906239\n"
          ]
        }
      ],
      "source": [
        "# Train/Predict with normalization\n",
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load magic telescope data\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "scaler = MinMaxScaler()\n",
        "np_arr[:, :-1] = scaler.fit_transform(np_arr[:, :-1])\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "y_train = np_arr[:,-1]\n",
        "\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "np_arr[:, :-1] = scaler.transform(np_arr[:, :-1])\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "# X_test = scaler.transform(X_test)\n",
        "y_test = np_arr[:,-1]\n",
        "\n",
        "col_type = ['real']*14\n",
        "col_type[3] = 'cat'\n",
        "# Train on training set\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type,weight_type='inverse_distance')\n",
        "knn_wt.fit(X=X_train, y=y_train, k=5)\n",
        "\n",
        "# Predict on test set\n",
        "print('inverse weighting mse: ', knn_wt.score_mse(X=X_test,y=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP459vycUR7F"
      },
      "source": [
        "*Discuss your results*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the magic telescope data, using inverse distance weighting improved the accuracy of the prediction by little (from 83.06% to 83.12%). Therefore, for the magic telescope data I don't know if we can say that iverse distance weighting improves accuracy significantly. \n",
        "\n",
        "For the housing data, the lowest MSE occured at k = 5 with the mse = 15.89. Inverse distance weighting for this housing data did seem to have a significant impact on the accuracy, with the MSE at k = 5 being 12.12 < 15.89."
      ],
      "metadata": {
        "id": "drI02_VGmOa6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-Oh86EgUR7F"
      },
      "source": [
        "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
        "\n",
        "- Use this [credit approval dataset](https://byu.instructure.com/courses/14142/files?preview=4660998)\n",
        "    - Use a 70/30 split of the data for the training/test set\n",
        "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
        "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
        "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
        "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
        "- Use your own choice for k.\n",
        "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def getSplit(arr,dec):\n",
        "  \"\"\"\n",
        "  the 'arr' arguement should be the full numpy array before it is split into X and y\n",
        "  \"\"\"\n",
        "  # THE NAMES OF THESE VARIABLES ARE AS IF THE SPLIT IS 80/20 BUT IT WORKS FOR ANY PERCENT BASED ON DEC (which is a decimal value)\n",
        "  rand_start_index = random.randint(0,arr.shape[0]-1)\n",
        "  num_vals_80 = round((arr.shape[0])*dec)\n",
        "  num_vals_20 = arr.shape[0] - num_vals_80\n",
        "  arr_80_combined = None\n",
        "  arr_20 = None\n",
        "  if (rand_start_index + num_vals_80) >= arr.shape[0]: # if the starting index (row) + the number of rows we need to make 80% of the rows >= the number of rows in arr\n",
        "    num_vals_from_start = (rand_start_index + num_vals_80) - arr.shape[0] - 1 # the number of rows past the last row (back to the first row) that we need to make 80%\n",
        "    arr_80_pt1 = arr[:num_vals_from_start,:] # part1 of the 80%_array from row[0] to row[num_vals_from_start - 1]\n",
        "    arr_80_pt2 = arr[rand_start_index:,:] # part2 of the 80%_array from the rand_start_index (row) to the last index (row)\n",
        "    arr_80_combined = np.concatenate((arr_80_pt1,arr_80_pt2), axis=0)\n",
        "    arr_20 = arr[num_vals_from_start:rand_start_index,:] # 20%_array is everything in between\n",
        "  else:\n",
        "    arr_80_combined = arr[rand_start_index:num_vals_80,:]\n",
        "    arr_20 = arr[num_vals_80:,:]\n",
        "  return arr_80_combined, arr_20"
      ],
      "metadata": {
        "id": "WwuevepDgSbr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "ZS__-AMWUR7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c86552a-4935-455a-804c-6d4081ec6374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inverse weighting accuracy:  0.782608695652174\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: RuntimeWarning: divide by zero encountered in true_divide\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Load dataset and split into train/test sets\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/credit_approval.arff')\n",
        "creditDF = pd.DataFrame(raw_data[0])\n",
        "\n",
        "cont_features = np.where(creditDF.dtypes == 'float64')[0]\n",
        "cat_features = np.where(creditDF.dtypes != 'float64')[0]\n",
        "creditDF.iloc[:, cont_features] = MinMaxScaler().fit_transform(creditDF.iloc[:, cont_features])\n",
        "\n",
        "\n",
        "np_arr = creditDF.to_numpy()\n",
        "\n",
        "# print(np_arr)\n",
        "\n",
        "enc = OrdinalEncoder()\n",
        "np_arr = enc.fit_transform(np_arr[:,cat_features])\n",
        "\n",
        "train, test = getSplit(np_arr,.7)\n",
        "\n",
        "X_train = train[:,:-1]\n",
        "y_train = train[:,-1].astype(int)\n",
        "X_test = test[:,:-1]\n",
        "y_test = test[:,-1].astype(int)\n",
        "\n",
        "col_type = ['cat','real','real','cat','cat','cat','cat','real','cat','cat','real','cat','cat','real','real','cat']\n",
        "# Train/Predict with normalization\n",
        "knn_wt = KNNClassifier(Type='classification',columntype=col_type,weight_type='inverse_distance')\n",
        "knn_wt.fit(X=X_train, y=y_train, k=7)\n",
        "\n",
        "# Train/Predict credit-approval\n",
        "print('inverse weighting accuracy: ', knn_wt.score(X=X_test,y=y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFH-0kqTUR7F"
      },
      "source": [
        "*Explain and justify your distance metric*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as a distance metric, I choose for continuous data to use euclidean distance; for nominal data I choose to return distance=1 if the attributes are different or if there is missing data; if the nominal data attribute in the training set equals the attribute in the test instance then distance = 0. The justification for using euclidean distance for continuous data is that is what we were instructed to do. This method for computing nominal distances was chosen because it is the method that we discussed in class, and because it normalizes the difference between nominal data by giving a distance of 1 between different attributes and a distance of 0 between similar attributes. "
      ],
      "metadata": {
        "id": "4_-h3yY9o1jj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBmeNQ7jvcQ"
      },
      "source": [
        "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
        "\n",
        "- Try out different hyperparameters to see how well you can do. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "OFQv70W2VyqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf7a4aa-02a4-4e7f-ca75-c32af7afbc9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best p: 1\n",
            "Best n_neighbors: 12\n",
            "Best weights: distance\n",
            "accuracy of best model:  0.8532853285328533\n"
          ]
        }
      ],
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Train/Predict magic telescope using scikit's KNN\n",
        "  # load the data and preprocess\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "enc = LabelEncoder()\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "col_type = ['real']*14\n",
        "col_type[3] = 'cat'\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "y_train = enc.fit_transform(np_arr[:,-1]) \n",
        "\n",
        "\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/magic_telescope_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "X_test = scaler.transform(X_test)\n",
        "y_test = enc.fit_transform(np_arr[:,-1])\n",
        "\n",
        "  #initialize the model\n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "  #List Hyperparameters that we want to tune.\n",
        "# leaf_size = list(range(1,20))\n",
        "n_neighbors = list(range(1,13))\n",
        "p=[1,2]\n",
        "wts=['uniform', 'distance']\n",
        "\n",
        "  #Convert to dictionary\n",
        "hyperparameters = dict(weights=wts, n_neighbors=n_neighbors, p=p)\n",
        "  #Use GridSearch\n",
        "clf = GridSearchCV(knn, hyperparameters, cv=10)\n",
        "  #Fit the model\n",
        "best_model = clf.fit(X_train, y_train)\n",
        "  #Print The value of best Hyperparameters\n",
        "# print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
        "print('Best p:', best_model.best_estimator_.get_params()['p']) # p: 1 --> manhattan; p:2 --> euclidean\n",
        "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors']) # best k\n",
        "print('Best weights:', best_model.best_estimator_.get_params()['weights']) # distance mean IDW, uniform means no weights\n",
        "\n",
        "print('accuracy of best model: ',best_model.score(X_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io.arff import loadarff \n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Train/Predict housing using scikit's KNN\n",
        "  # load the data and preprocess\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_train.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "\n",
        "np_arr = df_data.to_numpy()\n",
        "scaler = MinMaxScaler()\n",
        "np_arr[:, :-1] = scaler.fit_transform(np_arr[:, :-1])\n",
        "\n",
        "X_train = np_arr[:,:-1].astype(float)\n",
        "y_train = np_arr[:,-1]\n",
        "\n",
        "raw_data = loadarff('/content/drive/MyDrive/School/CS_472_MachLearning/labs/lab4_kNN/data/housing_test.arff')\n",
        "df_data = pd.DataFrame(raw_data[0])\n",
        "np_arr = df_data.to_numpy()\n",
        "np_arr[:, :-1] = scaler.transform(np_arr[:, :-1])\n",
        "\n",
        "X_test = np_arr[:,:-1].astype(float)\n",
        "y_test = np_arr[:,-1]\n",
        "\n",
        "col_type = ['real']*14\n",
        "col_type[3] = 'cat'\n",
        "\n",
        "\n",
        "  #initialize the model\n",
        "knn_reg = KNeighborsRegressor()\n",
        "\n",
        "  #List Hyperparameters that we want to tune.\n",
        "# leaf_size = list(range(1,20))\n",
        "n_neighbors = list(range(1,20))\n",
        "p=[1,2]\n",
        "wts=['uniform', 'distance']\n",
        "\n",
        "  #Convert to dictionary\n",
        "hyperparameters = dict(weights=wts, n_neighbors=n_neighbors, p=p)\n",
        "  #Use GridSearch\n",
        "clf = GridSearchCV(knn_reg, hyperparameters, cv=10)\n",
        "  #Fit the model\n",
        "best_model = clf.fit(X_train, y_train)\n",
        "  #Print The value of best Hyperparameters\n",
        "# print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
        "print('Best p:', best_model.best_estimator_.get_params()['p']) # p: 1 --> manhattan; p:2 --> euclidean\n",
        "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors']) # best k\n",
        "print('Best weights:', best_model.best_estimator_.get_params()['weights']) # distance mean IDW, uniform means no weights\n",
        "\n",
        "print('accuracy of best model: ',best_model.score(X_test,y_test))\n",
        "# for the gridsearch and printing I used code from here https://medium.datadriveninvestor.com/k-nearest-neighbors-in-python-hyperparameters-tuning-716734bc557f"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_aQNFFSgXDN",
        "outputId": "9cb719b0-1871-4e7b-8cae-85497e9d4e30"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best p: 1\n",
            "Best n_neighbors: 4\n",
            "Best weights: distance\n",
            "accuracy of best model:  0.8595764828109167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqSFAXwlk3Ms"
      },
      "source": [
        "*Report your comparison*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the KNN Classifier on the magic telescope data, I used a grid search to find the best hyperparameters of weight type (idw, uniform), distance type (p: manhattan, euclidean), and number of neighbors (k). It was found that for the magic telescope data with the KNNClassifier that the best distance type (p:1) for the model was manhattan distance, with k=12 neighbors, and inverse distance weighting. \n",
        "\n",
        "For the housing data I also used grid search to find the best hyperparameters which were also weight type (idw, uniform), distance type (p: manhattan, euclidean), and number of neighbors (k). For the housing data, the best model also used manhattan distance (p:1), k=4 nearest neighbors, and inverse distance weighting as well.\n",
        "\n",
        "I'll note that the KNNRegressor model on the housing data ran much quicker than the KNNClassifier did. The reason is probably that the classification has more computation steps than the regression does."
      ],
      "metadata": {
        "id": "8SkTFLknq-s-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTlK-kijk8Mg"
      },
      "source": [
        "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
        "\n",
        "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
        "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
        "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
        "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
        "    - Examples of reduction techniques include: (a) leave-one-out reduction - Drop instance if it would still be classified correctly, (b) growth algorithm - Only add instance if it is not already classified correctly, (c) just keep central points, (d) just keep border points, etc. (see Wilson, D. R. and Martinez, T. R., Reduction Techniques for Exemplar-Based Learning Algorithms, Machine Learning Journal, vol. 38, no. 3, pp. 257-286, 2000)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "lab_4_knn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}